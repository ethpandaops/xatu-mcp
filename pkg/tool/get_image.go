package tool

import (
	"context"
	"encoding/base64"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/mark3labs/mcp-go/mcp"
	"github.com/sirupsen/logrus"
)

const (
	// GetImageToolName is the name of the get_image tool.
	GetImageToolName = "get_image"
	// maxImageSize is the maximum image size to download (10MB).
	maxImageSize = 10 * 1024 * 1024
	// imageDownloadTimeout is the timeout for downloading images.
	imageDownloadTimeout = 30 * time.Second
)

// supportedImageTypes maps file extensions to MIME types.
var supportedImageTypes = map[string]string{
	".png":  "image/png",
	".jpg":  "image/jpeg",
	".jpeg": "image/jpeg",
	".gif":  "image/gif",
	".webp": "image/webp",
	".svg":  "image/svg+xml",
}

// getImageDescription describes the get_image tool.
const getImageDescription = `Fetch an image from storage and return it for inline display.

Use this tool to view images that were generated by Python code and uploaded via storage.upload().

Example workflow:
1. Run execute_python to generate and upload a chart
2. Get the URL from stdout (e.g., "Chart: https://...")
3. Call get_image with that URL to view the image inline

Only URLs from the configured storage endpoint are allowed.`

// GetImageConfig holds configuration for the get_image tool.
type GetImageConfig struct {
	// PublicURLPrefix is the allowed URL prefix for image downloads.
	// Only URLs starting with this prefix will be fetched.
	PublicURLPrefix string
	// InternalURLPrefix is the internal URL prefix used for fetching.
	// If set, the PublicURLPrefix in URLs will be replaced with this.
	// This is useful when running in Docker where localhost URLs need
	// to be rewritten to use internal service names.
	InternalURLPrefix string
}

// NewGetImageTool creates the get_image tool definition.
func NewGetImageTool(log logrus.FieldLogger, cfg GetImageConfig) Definition {
	return Definition{
		Tool: mcp.Tool{
			Name:        GetImageToolName,
			Description: getImageDescription,
			InputSchema: mcp.ToolInputSchema{
				Type: "object",
				Properties: map[string]any{
					"url": map[string]any{
						"type":        "string",
						"description": "The URL of the image to fetch (must be from storage.upload())",
					},
				},
				Required: []string{"url"},
			},
		},
		Handler: newGetImageHandler(log, cfg),
	}
}

// newGetImageHandler creates the handler function for get_image.
func newGetImageHandler(log logrus.FieldLogger, cfg GetImageConfig) Handler {
	handlerLog := log.WithField("tool", GetImageToolName)

	return func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
		// Extract URL from arguments.
		url, err := request.RequireString("url")
		if err != nil {
			return CallToolError(fmt.Errorf("invalid arguments: %w", err)), nil
		}

		if url == "" {
			return CallToolError(fmt.Errorf("url is required")), nil
		}

		handlerLog.WithField("url", url).Debug("Fetching image")

		// Validate URL is from allowed storage.
		if err := validateImageURL(url, cfg.PublicURLPrefix); err != nil {
			return CallToolError(err), nil
		}

		// Determine MIME type from URL.
		mimeType, err := getMIMETypeFromURL(url)
		if err != nil {
			return CallToolError(err), nil
		}

		// Rewrite URL for internal fetching if configured.
		fetchURL := url
		if cfg.InternalURLPrefix != "" {
			fetchURL = strings.Replace(url, cfg.PublicURLPrefix, cfg.InternalURLPrefix, 1)
			handlerLog.WithFields(logrus.Fields{
				"original_url": url,
				"fetch_url":    fetchURL,
			}).Debug("Rewrote URL for internal fetching")
		}

		// Download the image.
		data, err := downloadImage(ctx, fetchURL)
		if err != nil {
			handlerLog.WithError(err).Error("Failed to download image")

			return CallToolError(fmt.Errorf("failed to download image: %w", err)), nil
		}

		// Base64 encode the image.
		encoded := base64.StdEncoding.EncodeToString(data)

		handlerLog.WithFields(logrus.Fields{
			"url":       url,
			"mime_type": mimeType,
			"size":      len(data),
		}).Info("Image fetched successfully")

		return CallToolImage(encoded, mimeType), nil
	}
}

// validateImageURL validates that the URL is from the allowed storage prefix.
// This performs strict validation to prevent SSRF attacks:
// 1. Parses the URL to validate structure
// 2. Ensures the prefix ends with "/" to prevent prefix bypass (e.g., evil.com vs evil.com.attacker.com)
// 3. Validates scheme is https or http
func validateImageURL(rawURL string, allowedPrefix string) error {
	if allowedPrefix == "" {
		return fmt.Errorf("image fetching is not configured (no public_url_prefix set)")
	}

	// Ensure prefix ends with "/" to prevent bypass attacks.
	// e.g., prefix "https://storage.example.com" would match "https://storage.example.com.evil.com"
	// but "https://storage.example.com/" would not.
	normalizedPrefix := allowedPrefix
	if !strings.HasSuffix(normalizedPrefix, "/") {
		normalizedPrefix += "/"
	}

	// Parse the URL to validate structure.
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return fmt.Errorf("invalid URL: %w", err)
	}

	// Validate scheme.
	if parsedURL.Scheme != "http" && parsedURL.Scheme != "https" {
		return fmt.Errorf("URL scheme must be http or https, got: %s", parsedURL.Scheme)
	}

	// Reconstruct URL without query/fragment for prefix check.
	// This ensures we're checking the actual path, not query params.
	checkURL := fmt.Sprintf("%s://%s%s", parsedURL.Scheme, parsedURL.Host, parsedURL.Path)

	// Also need trailing slash handling for the check URL.
	if !strings.HasSuffix(checkURL, "/") && !strings.Contains(path.Base(parsedURL.Path), ".") {
		checkURL += "/"
	}

	// Check if URL starts with normalized prefix.
	if !strings.HasPrefix(checkURL+"/", normalizedPrefix) && !strings.HasPrefix(checkURL, normalizedPrefix) {
		return fmt.Errorf(
			"URL must start with the configured storage prefix: %s",
			allowedPrefix,
		)
	}

	return nil
}

// getMIMETypeFromURL determines the MIME type from the URL's file extension.
func getMIMETypeFromURL(url string) (string, error) {
	// Extract the path component and get the extension.
	ext := strings.ToLower(path.Ext(url))

	// Handle URLs with query parameters.
	if idx := strings.Index(ext, "?"); idx != -1 {
		ext = ext[:idx]
	}

	mimeType, ok := supportedImageTypes[ext]
	if !ok {
		return "", fmt.Errorf(
			"unsupported image type: %s (supported: png, jpg, jpeg, gif, webp, svg)",
			ext,
		)
	}

	return mimeType, nil
}

// noRedirectClient is an HTTP client that does not follow redirects.
// This prevents SSRF attacks where an attacker could redirect to internal URLs.
var noRedirectClient = &http.Client{
	Timeout: imageDownloadTimeout,
	CheckRedirect: func(_ *http.Request, _ []*http.Request) error {
		return http.ErrUseLastResponse
	},
}

// downloadImage fetches the image data from the given URL.
// It does not follow redirects to prevent SSRF attacks.
func downloadImage(ctx context.Context, imageURL string) ([]byte, error) {
	// Create a context with timeout.
	ctx, cancel := context.WithTimeout(ctx, imageDownloadTimeout)
	defer cancel()

	// Create the request.
	req, err := http.NewRequestWithContext(ctx, http.MethodGet, imageURL, nil)
	if err != nil {
		return nil, fmt.Errorf("creating request: %w", err)
	}

	// Execute the request without following redirects.
	resp, err := noRedirectClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("fetching URL: %w", err)
	}
	defer func() { _ = resp.Body.Close() }()

	// Reject redirects - they could be used for SSRF.
	if resp.StatusCode >= 300 && resp.StatusCode < 400 {
		return nil, fmt.Errorf("redirects are not allowed (got status %d)", resp.StatusCode)
	}

	// Check status code.
	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("unexpected status code: %d", resp.StatusCode)
	}

	// Check content length if available.
	if resp.ContentLength > maxImageSize {
		return nil, fmt.Errorf(
			"image too large: %d bytes (max %d bytes)",
			resp.ContentLength,
			maxImageSize,
		)
	}

	// Read the response body with size limit.
	limitedReader := io.LimitReader(resp.Body, maxImageSize+1)

	data, err := io.ReadAll(limitedReader)
	if err != nil {
		return nil, fmt.Errorf("reading response: %w", err)
	}

	// Check if we hit the limit.
	if len(data) > maxImageSize {
		return nil, fmt.Errorf(
			"image too large: exceeded %d bytes",
			maxImageSize,
		)
	}

	return data, nil
}
